---
title: "Homework 3"
author: "Clare Qian"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(p8105.datasets)
library(ggridges)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

### Problem 1

```{r}
data("instacart")
```

This dataset contains `r nrow(instacart)` rows and `r ncol(instacart)` columns. 

Observations are at the level of items in orders by user. There are user / order variables -- user ID, order ID, order day, and order hour. There are also item variable -- name, aisle, department, and some numeric codes. For the first observation, the order_id is 1 and the product_id is 49302. The item is Bulgarian Yogurt, which has been ordered before. The product is in the yogurt aisle and dairy eggs department. For the 4th observation, the order_id is also 1 and the product_id is 49683. The item is Cucumber Kirby, which hasn't been ordered before. The product is in the fresh vegetables aisle and produce department. These two items are ordered together by user 112108.

How many aisles are there, and which aisles are the most items ordered from?

```{r}
instacart %>%
  count(aisle) %>%
  arrange(desc(n))
```

Make a plot that shows the number of items ordered in each aisle, limiting this to aisles with more than 10000 items ordered. Arrange aisles sensibly, and organize your plot so others can read it.

```{r}
instacart %>%
  count(aisle) %>%
  filter(n > 10000) %>%
  mutate(
    aisle = factor(aisle),
    aisle = fct_reorder(aisle, n)
  ) %>%
  ggplot(aes(x = aisle, y = n)) +
  geom_point() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```

Make a table showing the three most popular items in each of the aisles “baking ingredients”, “dog food care”, and “packaged vegetables fruits”. Include the number of times each item is ordered in your table.

```{r}
instacart %>%
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>%
  group_by(aisle) %>%
  count(product_name) %>%
  mutate(rank = min_rank(desc(n))) %>%
  filter(rank < 4) %>%
  arrange(aisle, rank) %>%
  knitr::kable()
```

Make a table showing the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week; format this table for human readers (i.e. produce a 2 x 7 table).

```{r}
instacart %>%
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>%
  group_by(product_name, order_dow) %>%
  summarize(mean_hour = mean(order_hour_of_day)) %>%
  pivot_wider(
    names_from = order_dow,
    values_from = mean_hour
  )
```

### Problem 2

```{r}
accel = read.csv("./data/accel_data.csv") %>%
  janitor::clean_names() %>%
  pivot_longer(
    activity_1:activity_1440,
    names_to = "minute_of_day",
    names_prefix = "activity_",
    values_to = "activity_count"
  ) %>%
  mutate(
    weekday_vs_weekend = case_when(
      day %in% c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday") ~ "weekday",
      day %in% c("Saturday", "Sunday") ~ "weekend"
    ),
    minute_of_day = as.numeric(minute_of_day),
    day = as.factor(day)
  ) %>%
  select(week, day_id, day_name = day, everything())
```

The dataset accel contains `r nrow(accel)` observations and `r ncol(accel)` columns. Variables include week, day_id, day_name, minute_of_day, activity_count, and weekday_vs_weekend.

Aggregate accross minutes to create a total activity variable for each day, and create a table showing these totals.

```{r}
accel %>%
  group_by(week, day_name = forcats::fct_relevel(day_name, c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"))) %>%
  summarise(total_activity = sum(activity_count)) %>%
  knitr::kable()
```

According to the table, we can notice that the male usually had more activity accounts on Thursday, Friday, Saturday, and Sunday. Additionally, the activity count seems more stable in week 2 and week 3.

Accelerometer data allows the inspection activity over the course of the day. Make a single-panel plot that shows the 24-hour activity time courses for each day and use color to indicate day of the week. Describe in words any patterns or conclusions you can make based on this graph.

```{r}
accel %>%
  mutate(day_name = forcats::fct_relevel(day_name, c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"))) %>%
  ggplot(aes(x = minute_of_day, y = activity_count, color = day_name)) + 
  geom_smooth(se = FALSE) + 
  theme(legend.position = "bottom") +
  labs(
  title = "Activity plot",
    caption = "Data from the accel dataset"
  )
```

We can observe from the graph that the male tended to move more on Sunday noon and Friday night. On other days, the activity count of the male were relatively more stable.

### Problem 3

Do some data cleaning. Create separate variables for year, month, and day. Ensure observations for temperature, precipitation, and snowfall are given in reasonable units. For snowfall, what are the most commonly observed values? Why?

```{r}
data("ny_noaa")
nyweather = 
  ny_noaa %>%
  mutate(
    ny_noaa,
    prcp = prcp/10,
    tmax = as.numeric(tmax)/10,
    tmin = as.numeric(tmin)/10
  ) %>%
  janitor::clean_names() %>%
  drop_na() %>%
  separate(date, c("year", "month", "day"))
```

This dataset records the weather conditions for all New York stations from January 1, 1981 through December 31, 2010, which contains `r nrow(nyweather)` rows and `r ncol(nyweather)` columns. Variables include year, month, day, prcp (precipitation (mm)), snow (snowfall (mm)), snwd (snow depth (mm)), tmax (maximum temperature (degrees C)), and tmin (minimum temperature (degrees C)). The original dataset contains `r nrow(ny_noaa)` observations, and `r nrow(ny_noaa) - nrow(nyweather)` observations with missing data were removed, so missing data is an important issue. 

```{r}
nyweather %>%
  count(snow) %>%
  arrange(desc(n))
```

The most 3 commonly observed values is 0, 25, and 13 in order. Since snowfall is usually observed in winter. For most of the time, there is no snowfall.

Make a two-panel plot showing the average max temperature in January and in July in each station across years. Is there any observable / interpretable structure? Any outliers?

```{r}
nyweather %>%
  filter(month %in% c("01", "07")) %>%
  group_by(month, id, year) %>%
  summarise(n = mean(tmax)) %>%
  ggplot(aes(x = year, y = n, group = id)) +
  geom_point() + 
  geom_path() +
  facet_grid(. ~ month) +
  theme(legend.position = "none", axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +
  labs(y = "Average maximum temperature (C)")
```

First, the average max temperature in July of all years are higher than the average max temperature in January of all years. Outliers include Jan 1982, Jan 1996, Jan 1997, Jul 1988, Jul 2007, and so on. The data collected in July in different stations varies less, compared to the data collected in January. We can observe larger fluctuations in January temperature across years, compared to July temperature.